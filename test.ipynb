{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f0ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_model, Permute, Covxvit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "num_classes = 10\n",
    "# model = build_model(10, model=\"swin\").cpu()\n",
    "# premodel = build_model(10, model=\"convnext\").cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ba5f67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dNormActivation(\n",
       "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "    )\n",
       "    (1): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.014285714285714285, mode=row)\n",
       "    )\n",
       "    (2): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.04285714285714286, mode=row)\n",
       "    )\n",
       "    (1): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
       "    )\n",
       "    (2): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.07142857142857142, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
       "    )\n",
       "    (1): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "    )\n",
       "    (2): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
       "    )\n",
       "    (3): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.12857142857142856, mode=row)\n",
       "    )\n",
       "    (4): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
       "    )\n",
       "    (5): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.15714285714285714, mode=row)\n",
       "    )\n",
       "    (6): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
       "    )\n",
       "    (7): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.18571428571428572, mode=row)\n",
       "    )\n",
       "    (8): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "    )\n",
       "    (9): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.21428571428571427, mode=row)\n",
       "    )\n",
       "    (10): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.22857142857142856, mode=row)\n",
       "    )\n",
       "    (11): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.24285714285714285, mode=row)\n",
       "    )\n",
       "    (12): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2571428571428571, mode=row)\n",
       "    )\n",
       "    (13): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2714285714285714, mode=row)\n",
       "    )\n",
       "    (14): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2857142857142857, mode=row)\n",
       "    )\n",
       "    (15): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "    )\n",
       "    (16): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.3142857142857143, mode=row)\n",
       "    )\n",
       "    (17): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.32857142857142857, mode=row)\n",
       "    )\n",
       "    (18): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.34285714285714286, mode=row)\n",
       "    )\n",
       "    (19): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.35714285714285715, mode=row)\n",
       "    )\n",
       "    (20): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.37142857142857144, mode=row)\n",
       "    )\n",
       "    (21): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.38571428571428573, mode=row)\n",
       "    )\n",
       "    (22): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.4, mode=row)\n",
       "    )\n",
       "    (23): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.4142857142857143, mode=row)\n",
       "    )\n",
       "    (24): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.42857142857142855, mode=row)\n",
       "    )\n",
       "    (25): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.44285714285714284, mode=row)\n",
       "    )\n",
       "    (26): CNBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (6): Permute()\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.45714285714285713, mode=row)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vit = models.vit_l_16(weights = models.ViT_L_16_Weights.IMAGENET1K_V1)\n",
    "# cnn = models.convnext_large(weights=models.ConvNeXt_Large_Weights.IMAGENET1K_V1)\n",
    "# model = build_model(num_classes, model = \"covxnext\", meta = [10,10,10])\n",
    "# model(torch.zeros((16,3,224,224)), torch.zeros((16,3), dtype=torch.long))\n",
    "# model = build_model(10, model=\"conxvit\")\n",
    "# model(torch.zeros((2,3,224,224)))\n",
    "# cnn = models.convnext_large()\n",
    "cnn.features[:6]#(torch.zeros((1,3,224,224))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00483a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts: Counter({np.int32(1): 70, np.int32(0): 20, np.int32(2): 10})\n",
      "Class counts after resampling Counter({np.int32(0): 70, np.int32(1): 70, np.int32(2): 70})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B',\n",
       "        'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "        'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',\n",
       "        'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',\n",
       "        'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', 'B', 'A', 'A',\n",
       "        'A', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B',\n",
       "        'A', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'B', 'A',\n",
       "        'B', 'B', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B',\n",
       "        'B', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
       "        'D', 'D'], dtype=object),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([\"A\"] * 10 + [\"B\"] * 20 + [\"C\"] * 30 + [\"D\"] * 40, dtype=object).reshape(-1, 1)\n",
    "y = np.array([0] * 20 + [1] * 70 + [2] * 10, dtype=np.int32)\n",
    "from collections import Counter\n",
    "print(f\"Original class counts: {Counter(y)}\")\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "sampler = SMOTEN(random_state=0, sampling_strategy= {0:40, 1:70, 2:20})\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "print(f\"Class counts after resampling {Counter(y_res)}\")\n",
    "# X_res[:,0], y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa5d6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NV</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCC</td>\n",
       "      <td>50.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BKL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17726</th>\n",
       "      <td>BKL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17727</th>\n",
       "      <td>BCC</td>\n",
       "      <td>75.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17728</th>\n",
       "      <td>NV</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17729</th>\n",
       "      <td>BCC</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>BKL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17731 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  age_approx anatom_site_general     sex\n",
       "0        NV        30.0                 NaN  female\n",
       "1       BCC        50.0           head/neck    male\n",
       "2       MEL        65.0     posterior torso    male\n",
       "3       BKL        70.0           head/neck  female\n",
       "4       MEL        60.0           head/neck    male\n",
       "...     ...         ...                 ...     ...\n",
       "17726   BKL        70.0           head/neck  female\n",
       "17727   BCC        75.0           head/neck    male\n",
       "17728    NV        50.0      anterior torso    male\n",
       "17729   BCC        30.0      anterior torso  female\n",
       "17730   BKL        65.0     posterior torso    male\n",
       "\n",
       "[17731 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "class ISIC2019Dataset(Dataset):\n",
    "    def __init__(self, img_dir, csv_file, meta_file, transform=None, train = False, filter = True):\n",
    "        # Image directory and CSV file\n",
    "        self.img_dir = img_dir\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        meta = pd.read_csv(meta_file)\n",
    "        self.data = self.data.merge(meta, how='inner', on='image')\n",
    "        # print(self.data)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        # List of target classes\n",
    "        self.label_cols = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"]\n",
    "\n",
    "        if(filter):\n",
    "            self.label_num = [len(self.data[self.data[\"label\"] == label]) for label in self.label_cols]\n",
    "            filtered = []\n",
    "            self.count = {}\n",
    "            for label, number in zip(self.label_cols, self.label_num):\n",
    "                self.count[label] = number\n",
    "                if(number < 1000):\n",
    "                    filtered.append(label)\n",
    "            self.minor = filtered\n",
    "            self.label_num.sort()\n",
    "            self.minimum = self.label_num[int(len(self.label_num)/2)]\n",
    "            self.total = sum(self.label_num)\n",
    "            for label in self.minor:\n",
    "                self.count[label] = self.minimum\n",
    "            # self.data = pd.concat([self.data[self.data[\"label\"]==label]for label in filtered], ignore_index=True)\n",
    "\n",
    "        # Remove rows with unknown labels\n",
    "        if \"UNK\" in self.data.columns:\n",
    "            self.data = self.data[self.data[self.label_cols].sum(axis=1) > 0].reset_index(drop=True)\n",
    "dataset = ISIC2019Dataset(img_dir=\"data/Training\",\n",
    "                            csv_file=\"splits/train_split.csv\",\n",
    "                            meta_file=\"data/ISIC_2019_Training_Metadata.csv\")\n",
    "dataset.data[[\"label\", \"age_approx\", \"anatom_site_general\", \"sex\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "num_cols = [\"age_approx\"]\n",
    "cat_cols = [\"anatom_site_general\", \"sex\"]\n",
    "fill_na = {col: \"missing\" for col in cat_cols}\n",
    "fill_na[\"age_approx\"] =dataset.data[\"age_approx\"].median()\n",
    "dataset.data.fillna(fill_na, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cea77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_feature_indices = [1,2]\n",
    "\n",
    "pipe = SMOTENC(\n",
    "        categorical_features=cat_feature_indices,\n",
    "        random_state=42,\n",
    "        sampling_strategy=dataset.count\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "min_age, max_age = np.min(dataset.data[\"age_approx\"]), np.max(dataset.data[\"age_approx\"])\n",
    "def discretize(x):\n",
    "    return np.clip(np.round(x.astype(np.float16) / 5) * 5, min_age, max_age)\n",
    "\n",
    "X_res, y_res = pipe.fit_resample(dataset.data[[\"age_approx\", \"anatom_site_general\", \"sex\"]], dataset.data[[\"label\"]])\n",
    "X_res = X_res.replace(\"missing\", np.nan)\n",
    "X_res.iloc[dataset.total:, 0] = discretize(X_res.iloc[dataset.total:, 0])\n",
    "y_res = y_res[dataset.total:].values.ravel()\n",
    "df_resampled = pd.DataFrame(\n",
    "    X_res.iloc[dataset.total:, :],\n",
    "    columns=[\"age_approx\", \"anatom_site_general\", \"sex\"]\n",
    ")\n",
    "label_cols = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"]\n",
    "\n",
    "encoder = OneHotEncoder(categories=[label_cols], sparse_output=False)\n",
    "\n",
    "labels_encoded = encoder.fit_transform(pd.DataFrame(y_res, columns = [\"label\"]))\n",
    "\n",
    "df_onehot = pd.DataFrame(labels_encoded, columns = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"])\n",
    "df_resampled = df_resampled.reset_index(drop=True)\n",
    "df_onehot = df_onehot.reset_index(drop=True)\n",
    "df_merged = pd.concat([df_resampled, df_onehot], axis=1)\n",
    "df_merged[\"label\"] = y_res\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "df_merged.to_csv(\"splits/meta_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8e60a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MEL   NV  BCC   AK  BKL   DF  VASC  SCC\n",
      "0  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0\n",
      "1  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0\n",
      "2  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0\n",
      "3  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0\n",
      "4  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['label_MEL', 'label_NV', 'label_BCC', 'label_AK', 'label_BKL',\n",
       "       'label_DF', 'label_VASC', 'label_SCC'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_cols = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"]\n",
    "\n",
    "encoder = OneHotEncoder(categories=[label_cols], sparse_output=False)\n",
    "\n",
    "# 假設 df[\"label\"] 是你的標籤欄位\n",
    "labels_encoded = encoder.fit_transform(df_resampled[[\"label\"]])\n",
    "\n",
    "# 轉成 DataFrame\n",
    "df_onehot = pd.DataFrame(labels_encoded, columns = [\"MEL\", \"NV\", \"BCC\", \"AK\", \"BKL\", \"DF\", \"VASC\", \"SCC\"])\n",
    "\n",
    "print(df_onehot.head())\n",
    "encoder.get_feature_names_out([\"label\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
